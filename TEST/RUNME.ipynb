{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7a256d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the absolute path where the KIT_4_ABM folder is located\n",
    "global_path = 'C:/Users/nel_t/Documents/WORK/PROJECTS/a_KIT_4_ABM'   # <--- CHANGE THIS PATH to the one on your computer\n",
    "code_path   = global_path + '/SRC'   # <--- CHANGE THIS PATH to the one on your computer\n",
    "\n",
    "# import the KIT_4_ABM package\n",
    "import sys\n",
    "sys.path.append(code_path)\n",
    "import KIT_4_ABM as kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31083ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "parameters are: i= 0  n_trials= 1  P_rec= {'N': 1, 'note': \"the default is to save nothing, and the file name is 'none.txt' and it will be empty, default DT = 0, which means not to save anything runtime\", 'filename': 'SIRB_beta_0_02_01_h_0_betasymm_01.h5', 'Recording_0': {'END': 'True', 'DT': 1, 'func': 'frac', 'target_fraction': 3, 'layer': 0, 'target': 'behavior_status', 'name': 'R', 'total_count': 11, 'BEGIN': 'False', 'count': 11}}  results= <Save_Functions.Saves object at 0x000001ADB97C2A30>\n",
      "L= 11\n",
      " I should enter in write array\n",
      "saving_array\n",
      "key =  R\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object dtype dtype('O') has no native HDF5 equivalent",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:6\u001b[0m\n",
      "File \u001b[1;32mC:\\Users/nel_t/Documents/WORK/PROJECTS/a_KIT_4_ABM/SRC\\Save_Functions.py:248\u001b[0m, in \u001b[0;36mwrite_h5\u001b[1;34m(i, n_trials, P_rec, results)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m I should enter in write array\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    245\u001b[0m \u001b[39mif\u001b[39;00m L \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    246\u001b[0m     \u001b[39m# if the length of the array is > 1, save it as an array, and indipendently for each trial\u001b[39;00m\n\u001b[0;32m    247\u001b[0m     \u001b[39m# the name of the array will be: T_$i$_name\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m     write_array(filename, name_attr, i, Obj)\n\u001b[0;32m    249\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    251\u001b[0m     \u001b[39m# if the length of the array is 1, create an array and save it inside the i-th trial elements of the array\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     \u001b[39m# the name of the array will be: name\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users/nel_t/Documents/WORK/PROJECTS/a_KIT_4_ABM/SRC\\Save_Functions.py:224\u001b[0m, in \u001b[0;36mwrite_array\u001b[1;34m(name, key, i, value)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkey = \u001b[39m\u001b[39m\"\u001b[39m, key)\n\u001b[0;32m    223\u001b[0m key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTrial_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m key\n\u001b[1;32m--> 224\u001b[0m f\u001b[39m.\u001b[39;49mcreate_dataset(key, data\u001b[39m=\u001b[39;49mvalue, chunks\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, maxshape\u001b[39m=\u001b[39;49m(\u001b[39mNone\u001b[39;49;00m,))\n",
      "File \u001b[1;32mc:\\Users\\nel_t\\anaconda3\\envs\\ABM_4_KIT2\\lib\\site-packages\\h5py\\_hl\\group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    180\u001b[0m         parent_path, name \u001b[39m=\u001b[39m name\u001b[39m.\u001b[39mrsplit(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    181\u001b[0m         group \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequire_group(parent_path)\n\u001b[1;32m--> 183\u001b[0m dsid \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmake_new_dset(group, shape, dtype, data, name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    184\u001b[0m dset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mDataset(dsid)\n\u001b[0;32m    185\u001b[0m \u001b[39mreturn\u001b[39;00m dset\n",
      "File \u001b[1;32mc:\\Users\\nel_t\\anaconda3\\envs\\ABM_4_KIT2\\lib\\site-packages\\h5py\\_hl\\dataset.py:86\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     85\u001b[0m         dtype \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mdtype(dtype)\n\u001b[1;32m---> 86\u001b[0m     tid \u001b[39m=\u001b[39m h5t\u001b[39m.\u001b[39;49mpy_create(dtype, logical\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     88\u001b[0m \u001b[39m# Legacy\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m((compression, shuffle, fletcher32, maxshape, scaleoffset)) \u001b[39mand\u001b[39;00m chunks \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[1;32mh5py\\h5t.pyx:1664\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5t.pyx:1688\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5t.pyx:1748\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object dtype dtype('O') has no native HDF5 equivalent"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "P_lay, P_dyn, P_sim, P_rec = kit.import_parameters(\"PAR_desired.json\")\n",
    "n_trials = 1\n",
    "for i in range(n_trials):\n",
    "    print(i)\n",
    "    res = kit.run_sim(P_lay, P_dyn, P_sim, P_rec)\n",
    "    kit.write_h5(i, n_trials, P_rec, res)\n",
    "\n",
    "print(res.R.data)\n",
    "print(len(res.R.time))\n",
    "print(res.R.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ae578d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R']\n"
     ]
    }
   ],
   "source": [
    "attrs = [a for a in dir(res) if not a.startswith('_')]\n",
    "print(attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b38a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R\n"
     ]
    }
   ],
   "source": [
    "for attr, value in res.__dict__.items():\n",
    "    print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "582b29aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to convert an np.array \"a\" of dtype=object to a np.array \"b\" of dtype=float\n",
    "import numpy as np\n",
    "b = np.array(a, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3909d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d6b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f69ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the \"SIRB_beta_0_02_01_h_0_betasymm_01.h5\" file:\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "filename = \"SIRB_beta_0_02_01_h_0_betasymm_01.h5\"\n",
    "with h5py.File(filename, 'r') as file:\n",
    "    # Define a function to print dataset names\n",
    "    def print_dataset_names(name):\n",
    "        if isinstance(file[name], h5py.Dataset):\n",
    "            print(name)\n",
    "\n",
    "    # Visit all items in the file to print dataset names\n",
    "    file.visit(print_dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8429d980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N': 3, 'note': \"the default is to save nothing, and the file name is 'none.txt' and it will be empty, default DT = 0, which means not to save anything runtime\", 'filename': 'SIRB_beta_0_02_01_h_0_betasymm_01.txt', 'Recording_0': {'END': 'True', 'func': 'frac', 'target_fraction': 3, 'layer': 0, 'target': 'health_status', 'name': 'R', 'BEGIN': 'False', 'DT': 0, 'DATA': array([0.63], dtype=object), 'count': 1}, 'Recording_1': {'END': 'True', 'func': 'homophily', 'layer': 0, 'target': 'behavior_status', 'name': 'H', 'BEGIN': 'False', 'DT': 0, 'DATA': array([0.005136907141887859], dtype=object), 'count': 1}, 'Recording_2': {'END': 'True', 'func': 'variance', 'layer': 0, 'target': 'behavior_status', 'name': 'V', 'BEGIN': 'False', 'DT': 0, 'DATA': array([0.212297541527367], dtype=object), 'count': 1}}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14edd291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(filename, 'r') as file:\n",
    "    # print all the names of the datasets in the file\n",
    "    print(list(file.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90241fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([inf])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.R_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab114d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level items in the HDF5 file:\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "file_path = \"SIRB_beta_0_02_01_h_0_betasymm_01.h5\"  # Replace with the path to your HDF5 file\n",
    "with h5py.File(file_path, 'r') as file:\n",
    "    # List all the top-level groups or datasets in the file\n",
    "    print(\"Top-level items in the HDF5 file:\")\n",
    "    for item_name in file:\n",
    "        print(item_name)\n",
    "\n",
    "    # You can also inspect the type and shape of datasets if they exist\n",
    "    dataset_name = 'dataset_name'  # Replace with the actual dataset name\n",
    "    if dataset_name in file:\n",
    "        dataset = file[dataset_name]\n",
    "        print(f\"Dataset '{dataset_name}' information:\")\n",
    "        print(f\"Shape: {dataset.shape}\")\n",
    "        print(f\"Data type: {dataset.dtype}\")\n",
    "\n",
    "    # You can also inspect attributes of datasets or groups\n",
    "    group_name = 'group_name'  # Replace with the actual group name\n",
    "    if group_name in file:\n",
    "        group = file[group_name]\n",
    "        print(f\"Attributes of group '{group_name}':\")\n",
    "        for attr_name, attr_value in group.attrs.items():\n",
    "            print(f\"{attr_name}: {attr_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecd9dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0417f367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c37a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73451872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad5119c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.99383692, 0.86884735, 0.3068987 ])\n",
      " array([0.26168801, 0.87079567, 0.29780181])\n",
      " array([0.8671568 , 0.33569018, 0.27408986])\n",
      " array([0.77231458, 0.6344441 , 0.36432713])\n",
      " array([0.3681716 , 0.78590602, 0.81312859])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = 5  # Number of elements in the outer array\n",
    "L = 3  # Length of each inner array\n",
    "\n",
    "# Create an empty array to hold the result\n",
    "result = np.empty(N, dtype=object)\n",
    "\n",
    "# Fill the array with arrays of length L\n",
    "for i in range(N):\n",
    "    result[i] = np.random.rand(L)  # You can use np.zeros(L) or any other array creation method here\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e5207f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb20e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.empty(N, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13b8bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0] = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34249c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d27ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
